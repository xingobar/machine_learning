{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    print 'Loading data....'\n",
    "    with open('/Users/xingobar/Downloads/mnist.pkl', 'rb') as f:\n",
    "        train_data,validation_data,test_data = pickle.load(f)\n",
    "    \n",
    "    def share_dataset(data,borrow=True):\n",
    "        data_x,data_y = data\n",
    "        shared_x = theano.shared(np.asarray(data_x,dtype=theano.config.floatX),borrow=borrow)\n",
    "        shared_y = theano.shared(np.asarray(data_y,dtype=theano.config.floatX),borrow=borrow)\n",
    "        return shared_x,shared_y\n",
    "    \n",
    "    train_x,train_y = share_dataset(train_data)\n",
    "    validation_x,validation_y = share_dataset(validation_data)\n",
    "    test_x,test_y = share_dataset(test_data)\n",
    "    flatten = [(train_x,theano.tensor.cast(train_y.flatten(),'int32')),\n",
    "               (validation_x,theano.tensor.cast(validation_y.flatten(),'int32')),\n",
    "               (test_x,theano.tensor.cast(test_y.flatten(),'int32'))]\n",
    "    return flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LogisticRegressioin(object):\n",
    "    def __init__(self,input,n_in,n_out):\n",
    "        self.W = theano.shared(np.zeros((n_in,n_out),dtype=theano.config.floatX),name='weight',borrow=True)\n",
    "        self.b = theano.shared(np.zeros((n_out),dtype=theano.config.floatX),name='bias',borrow=True)\n",
    "        self.y_prob_given_x  =  theano.tensor.nnet.softmax(theano.tensor.dot(input,self.W) + self.b)\n",
    "        self.y_pred = theano.tensor.argmax(self.y_prob_given_x,axis=1) \n",
    "        self.params = [self.W,self.b]\n",
    "        self.input = input\n",
    "    \n",
    "    def negative_log_likelihood(self,y):\n",
    "        return -theano.tensor.mean(theano.tensor.log(self.y_prob_given_x)[theano.tensor.arange(y.shape[0]),y])\n",
    "    \n",
    "    def error(self,y):\n",
    "        if y.dtype.startswith('int'):\n",
    "            return theano.tensor.mean(theano.tensor.neq(self.y_pred,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data....\n",
      "number of training batches :  2500\n"
     ]
    }
   ],
   "source": [
    "batch_size = 20\n",
    "dataset = load_data()\n",
    "train_x,train_y = dataset[0]\n",
    "validation_x,validation_y = dataset[1]\n",
    "n_train_batch = train_x.get_value(borrow=True).shape[0] / batch_size\n",
    "n_validation_batch  = validation_x.get_value(borrow=True).shape[0] / batch_size \n",
    "print 'number of training batches : ' , n_train_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building the model....\n",
      "complete the training model\n"
     ]
    }
   ],
   "source": [
    "print 'building the model....'\n",
    "index = theano.tensor.lscalar()\n",
    "learning_rate = 0.01\n",
    "x = theano.tensor.matrix('x')\n",
    "y =  theano.tensor.ivector('y')\n",
    "classifier = LogisticRegressioin(input = x , n_in = 28*28,n_out = 10)\n",
    "cost  = classifier.negative_log_likelihood(y)\n",
    "\n",
    "validation_model = theano.function(\n",
    "inputs = [index],\n",
    "outputs = classifier.error(y),\n",
    "givens = {\n",
    "        x:validation_x[index * batch_size : (index+1) * batch_size],\n",
    "        y:validation_y[index * batch_size : (index+1) * batch_size]\n",
    "    }\n",
    ")\n",
    "g_w = theano.tensor.grad(cost=cost,wrt=classifier.W)\n",
    "g_b = theano.tensor.grad(cost=cost,wrt=classifier.b)\n",
    "\n",
    "updates = [(classifier.W, classifier.W - learning_rate * g_w),\n",
    "           (classifier.b,classifier.b - learning_rate * g_b)]\n",
    "\n",
    "train_model = theano.function(\n",
    "inputs = [index],\n",
    "outputs = cost,\n",
    "updates = updates,\n",
    "givens = {\n",
    "        x:train_x[index * batch_size : (index+1) * batch_size],\n",
    "        y:train_y[index * batch_size : (index+1) * batch_size]\n",
    "    }\n",
    ")\n",
    "print 'complete the training model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
